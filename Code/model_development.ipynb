{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pseudo_dreg01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHfJVBorrok_"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "from google.colab import drive\n",
        "from datetime import datetime"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4vxPR5wsAr3",
        "outputId": "7da293a0-fa06-4800-de24-696dbd85f4bd"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "root_path = 'drive/My Drive/KU/Robin_lab_project' \n",
        "os.chdir(root_path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkuqXoplD9In"
      },
      "source": [
        "# Data exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2C6dh1Djb3G"
      },
      "source": [
        "# Load data \n",
        "profiles_all = pd.read_csv(\"Data/ML_input/profiles_all_replicate_negfiltered.csv\")\n",
        "metadata_all = pd.read_csv(\"Data/ML_input/metadata_all_replicate_negfiltered.csv\")\n",
        "\n",
        "X = profiles_all.drop(\"label\", axis=1)\n",
        "X = StandardScaler().fit_transform(X)\n",
        "y = profiles_all[\"label\"]\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Hh0bPPvD6eH"
      },
      "source": [
        "#  PCA plot\n",
        "def multi_plot_pca(x, y, \n",
        "                   nrows=2, xlim=(-23,43), ylim=(-23,23),\n",
        "                   figsize=(12,7), top=0.89,\n",
        "                   title=\"\", save=False, filename=\"pca\"):\n",
        "  # Perform PCA and MDS\n",
        "  n_pcs = nrows*3+1\n",
        "  pca = PCA(n_components=n_pcs)\n",
        "  pcs = pca.fit_transform(x)\n",
        "  var = pca.explained_variance_ratio_ * 100\n",
        "  tmp_df = pd.concat([pd.DataFrame(pcs), y], axis = 1)\n",
        "  targets = [1,0]\n",
        "  colors = [\"r\",\"g\"]\n",
        "  # Plot fig and axes\n",
        "  fig, axes = plt.subplots(nrows, 3, figsize = figsize, sharex=True, sharey=True)\n",
        "  fig.add_subplot(111, frameon=False)\n",
        "  for target, color in zip(targets,colors):\n",
        "    i_keep = tmp_df['label'] == target\n",
        "    for i ,ax in enumerate(axes.flatten()):\n",
        "      ax.scatter(tmp_df.loc[i_keep,i], tmp_df.loc[i_keep,i+1], zorder=3, \n",
        "                      ec=\"black\", c=color, s=25, alpha = 0.8, label = target) \n",
        "      ax.set_title(f\"PC{i+1} ({var[i]:.2}%) and PC{i+2} ({var[i+1]:.2}%)\")\n",
        "      ax.set_xlim(xlim)\n",
        "      ax.set_ylim(ylim)\n",
        "  # Details\n",
        "  legend = ax.legend(frameon = 1, shadow = True, bbox_to_anchor=(1.3, 1.25))\n",
        "  frame = legend.get_frame()\n",
        "  frame.set_facecolor('white')\n",
        "  frame.set_edgecolor('black')\n",
        "  plt.tick_params(labelcolor='none', top=False, bottom=False, left=False, right=False)\n",
        "  fig.suptitle(f\"PCA first {n_pcs} PCs{title}\", fontsize=16)\n",
        "  plt.xlabel(\"First (relative) component\", fontsize=13)\n",
        "  plt.ylabel(\"Second (relative) component\", fontsize=13)\n",
        "  fig.tight_layout()\n",
        "  fig.subplots_adjust(top=top)\n",
        "  if save == True:\n",
        "      plt.savefig(f\"{filename}.png\", dpi = 300)\n",
        "  plt.show()\n",
        "\n",
        "multi_plot_pca(X, y, nrows=3, figsize=(12,12), top=0.92, \n",
        "               save=True, filename=\"Plots/pca_multiplot_allchr_all_replicate_negFiltered\")     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VB6G7X9REBC5"
      },
      "source": [
        "# Models development\n",
        "\n",
        "### Split train and test by chromosomes number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFgO34ijsmmL"
      },
      "source": [
        "# Load data divded by chr number\n",
        "profiles_train = pd.read_csv(\"Data/ML_input/profiles_all_replicate_negfiltered_train.csv\")\n",
        "profiles_test = pd.read_csv(\"Data/ML_input/profiles_all_replicate_negfiltered_test.csv\")\n",
        "metadata_train = pd.read_csv(\"Data/ML_input/metadata_all_replicate_negfiltered_train.csv\")\n",
        "metadata_test = pd.read_csv(\"Data/ML_input/metadata_all_replicate_negfiltered_test.csv\")\n",
        "\n",
        "# Divide predictor and target\n",
        "X_TRAIN = profiles_train.drop(\"label\", axis = 1)\n",
        "y_TRAIN = profiles_train[\"label\"]\n",
        "X_TEST = profiles_test.drop(\"label\", axis = 1)\n",
        "y_TEST = profiles_test[\"label\"]\n",
        "\n",
        "# # Normalization\n",
        "# scaler = StandardScaler()\n",
        "# X_TRAIN = scaler.fit_transform(X_TRAIN)\n",
        "# X_TEST = scaler.transform(X_TEST)\n",
        "\n",
        "print(X_TRAIN.shape)\n",
        "print(y_TRAIN.shape)\n",
        "print(X_TEST.shape)\n",
        "print(y_TEST.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE_BbkAEjfkT"
      },
      "source": [
        "def get_accuracy(ypred, y):\n",
        "  return sum(ypred == y) / len(y)\n",
        "\n",
        "def rmse(yprob, y):\n",
        "  return np.sqrt(np.mean((yprob-y)**2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2jMqXX_qsRF"
      },
      "source": [
        "\n",
        "##### Randomly split TRAIN into train and validation keeping labels proportion (it can be use as direct validation in alternative to CV)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USfYbT3rqlAH"
      },
      "source": [
        "# Split training set into train and validation\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=20)\n",
        "sss.split(X_TRAIN, y_TRAIN)\n",
        "\n",
        "for itrain, ival in sss.split(X_TRAIN, y_TRAIN):\n",
        "  X_train, X_val = X_TRAIN.iloc[itrain], X_TRAIN.iloc[ival]\n",
        "  y_train, y_val = y_TRAIN[itrain], y_TRAIN[ival]\n",
        "\n",
        "# Normalization\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq3Y4AtHD1O2"
      },
      "source": [
        "## Random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-hTgi6P2W2Y"
      },
      "source": [
        "def rf_train_pred(xtrain, ytrain, xtest, ytest, n_tree=100, name=\"RF\"):\n",
        "  start_time = datetime.now()\n",
        "  # Train\n",
        "  model = RandomForestClassifier(n_estimators=n_tree, bootstrap=True)\n",
        "  model.fit(xtrain, ytrain)\n",
        "  # Predict\n",
        "  ytrain_pred = model.predict(xtrain)\n",
        "  ytrain_prob = model.predict_proba(xtrain)[:,1]\n",
        "  ytest_pred = model.predict(xtest)\n",
        "  ytest_prob = model.predict_proba(xtest)[:,1]\n",
        "  # Evaluate\n",
        "  print(f\"{name} train accuracy: {get_accuracy(ytrain_pred, ytrain):.4}\")\n",
        "  print(f\"{name} test accuracy: {get_accuracy(ytest_pred, ytest):.4}\")\n",
        "  # Report time \n",
        "  print(f\"Duration: {datetime.now() - start_time}\")\n",
        "  return model, ytrain_prob, ytrain_pred, ytest_prob, ytest_pred,\n",
        "\n",
        "rf_model, rf_train_yprob, rf_train_ypred, rf_val_yprob, rf_val_ypred = rf_train_pred(X_train, y_train, X_val, y_val)   \n",
        "#0.6559 (real test)  # 0.67624 (splitted train into train and val) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxPuOa0YsFVb"
      },
      "source": [
        "# Random forest CV\n",
        "def rf_cv(xtrain, ytrain, n_tree=100, kfold=10, name=\"RF\"):\n",
        "  start_time = datetime.now()\n",
        "  print(f\"Performing {name} CV\")\n",
        "  # Initialize arrays to store predictions and true values\n",
        "  train_yprob_vec, train_ypred_vec, train_ytrue_vec = np.array([]), np.array([]), np.array([])\n",
        "  val_yprob_vec, val_ypred_vec, val_ytrue_vec = np.array([]), np.array([]), np.array([])\n",
        "  # Stratified CV\n",
        "  skf = StratifiedKFold(n_splits=kfold, shuffle=True, random_state=26)\n",
        "  for i, (itrain, ival) in enumerate(skf.split(xtrain, ytrain)):\n",
        "    print(f\"\\n> Starting CV iteration {i+1}\")\n",
        "    # Split data according to folds\n",
        "    X_train, X_val = xtrain.iloc[itrain], xtrain.iloc[ival]\n",
        "    y_train, y_val = ytrain.iloc[itrain], ytrain.iloc[ival]\n",
        "    # Normalization\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val = scaler.transform(X_val)\n",
        "    # Train and predict\n",
        "    _, train_yprob, train_ypred, val_yprob, val_ypred = rf_train_pred(X_train, y_train, X_val, y_val, n_tree)\n",
        "    # Store prediction on training data\n",
        "    train_yprob_vec = np.concatenate((train_yprob_vec, train_yprob))\n",
        "    train_ypred_vec = np.concatenate((train_ypred_vec, train_ypred))\n",
        "    train_ytrue_vec = np.concatenate((train_ytrue_vec, y_train))\n",
        "    # Store prediction on validation data\n",
        "    val_yprob_vec = np.concatenate((val_yprob_vec, val_yprob))\n",
        "    val_ypred_vec = np.concatenate((val_ypred_vec, val_ypred))\n",
        "    val_ytrue_vec = np.concatenate((val_ytrue_vec, y_val))\n",
        "  # Stack training and validation predictions into two panda df\n",
        "  train_output = pd.DataFrame({\"yprob\": train_yprob_vec, \"ypred\": train_ypred_vec,\"ytrue\": train_ytrue_vec})\n",
        "  val_output = pd.DataFrame({\"yprob\": val_yprob_vec, \"ypred\": val_ypred_vec,\"ytrue\": val_ytrue_vec})\n",
        "  # Evaluate\n",
        "  train_acc = get_accuracy(train_output[\"ypred\"].values, train_output[\"ytrue\"].values)\n",
        "  val_acc = get_accuracy(val_output[\"ypred\"].values, val_output[\"ytrue\"].values)\n",
        "  print(f\"\\n>> {name} final report\")\n",
        "  print(f\"Train CV accuracy: {train_acc:.4}\")\n",
        "  print(f\"Valid CV accuracy: {val_acc:.4}\")\n",
        "  # Report time \n",
        "  print(f\"Duration: {datetime.now() - start_time}\")\n",
        "  return train_output, val_output\n",
        "\n",
        "rf_train_output, rf_val_output = rf_cv(X_TRAIN, y_TRAIN)\n",
        "display(rf_val_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utACh3uwD3Vq"
      },
      "source": [
        "## LightGBM    \n",
        "### >> Should validate on validation data <<\n",
        "Should split train into training and validation keeping both labels and chr proportion "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0qvhNGgf-Ys"
      },
      "source": [
        "def lgb_train_pred(xtrain, ytrain, xtest, ytest, par, name=\"LGBM\"):\n",
        "  start_time = datetime.now()\n",
        "  # Train\n",
        "  train_data = lgb.Dataset(xtrain , label = ytrain)\n",
        "  valid_data = lgb.Dataset(xtest, label = ytest)\n",
        "  model = lgb.train(par, train_data, valid_sets=[valid_data], verbose_eval=20) \n",
        "  # Predict\n",
        "  ytrain_prob = model.predict(np.array(xtrain))\n",
        "  ytrain_pred = np.round(ytrain_prob)\n",
        "  ytest_prob = model.predict(np.array(xtest))\n",
        "  ytest_pred = np.round(ytest_prob)\n",
        "  # Evaluate\n",
        "  print(f\"{name} train accuracy: {get_accuracy(ytrain_pred, ytrain):.4}\")\n",
        "  print(f\"{name} test accuracy: {get_accuracy(ytest_pred, ytest):.4}\")\n",
        "  # Report time \n",
        "  print(f\"Duration: {datetime.now() - start_time}\")\n",
        "  return model, ytrain_prob, ytrain_pred, ytest_prob, ytest_pred\n",
        "\n",
        "params = {\"application\" : \"binary\",\n",
        "          \"num_boost_round\" : 400,\n",
        "         # \"metric\" :\"binary_logloss\",\n",
        "          \"metric\" :\"rmse\",\n",
        "          \"force_row_wise\" : True,\n",
        "          \"learning_rate\" : 0.009,            \n",
        "         # \"sub_feature\" : 0.8,\n",
        "         # \"sub_row\" : 0.75,\n",
        "         # \"bagging_freq\" : 1,\n",
        "         # \"lambda_l2\" : 0.1,\n",
        "         # 'verbosity': 1,\n",
        "          'num_iterations' : 1500\n",
        "         # 'num_leaves': 128,\n",
        "         # \"min_data_in_leaf\": 100,\n",
        "}\n",
        "\n",
        "lgb_model, lgb_train_yprob, lgb_train_ypred, lgb_val_yprob, lgb_val_ypred = lgb_train_pred(X_train, y_train, X_val, y_val, params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMTWndORf3aE"
      },
      "source": [
        "# LGBM CV\n",
        "def lgb_cv(xtrain, ytrain, par, kfold=10, name=\"LGBM\"):\n",
        "  start_time = datetime.now()\n",
        "  print(f\"Performing {name} CV\")\n",
        "  # Initialize 1d df to store predictions and true values\n",
        "  train_yprob_vec, train_ypred_vec, train_ytrue_vec = np.array([]), np.array([]), np.array([])\n",
        "  val_yprob_vec, val_ypred_vec, val_ytrue_vec = np.array([]), np.array([]), np.array([])\n",
        "  # Stratified CV\n",
        "  skf = StratifiedKFold(n_splits=kfold, shuffle=True, random_state=26)\n",
        "  for i, (itrain, ival) in enumerate(skf.split(xtrain, ytrain)):\n",
        "    print(f\"\\n> Starting CV iteration {i+1}\")\n",
        "    # Split data according to folds\n",
        "    X_train, X_val = xtrain.iloc[itrain], xtrain.iloc[ival]\n",
        "    y_train, y_val = ytrain.iloc[itrain], ytrain.iloc[ival]\n",
        "    # Normalization\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val = scaler.transform(X_val)\n",
        "    # Train and predict\n",
        "    _, train_yprob, train_ypred, val_yprob, val_ypred = lgb_train_pred(X_train, y_train, X_val, y_val, par=par)\n",
        "    # Store prediction on training data\n",
        "    train_yprob_vec = np.concatenate((train_yprob_vec, train_yprob))\n",
        "    train_ypred_vec = np.concatenate((train_ypred_vec, train_ypred))\n",
        "    train_ytrue_vec = np.concatenate((train_ytrue_vec, y_train))\n",
        "    # Store prediction on validation data\n",
        "    val_yprob_vec = np.concatenate((val_yprob_vec, val_yprob))\n",
        "    val_ypred_vec = np.concatenate((val_ypred_vec, val_ypred))\n",
        "    val_ytrue_vec = np.concatenate((val_ytrue_vec, y_val))\n",
        "  # Stack training and validation predictions into two panda df\n",
        "  train_output = pd.DataFrame({\"yprob\": train_yprob_vec, \"ypred\": train_ypred_vec,\"ytrue\": train_ytrue_vec})\n",
        "  val_output = pd.DataFrame({\"yprob\": val_yprob_vec, \"ypred\": val_ypred_vec,\"ytrue\": val_ytrue_vec})\n",
        "  # Evaluate\n",
        "  train_acc = get_accuracy(train_output[\"ypred\"].values, train_output[\"ytrue\"].values)\n",
        "  val_acc = get_accuracy(val_output[\"ypred\"].values, val_output[\"ytrue\"].values)\n",
        "  print(f\"\\n>> {name} final report\")\n",
        "  print(f\"Train CV accuracy: {train_acc:.4}\")\n",
        "  print(f\"Valid CV accuracy: {val_acc:.4}\")\n",
        "  # Report time \n",
        "  print(f\"Duration: {datetime.now() - start_time}\")\n",
        "  return train_output, val_output\n",
        "\n",
        "lgb_train_output, lgb_val_output = lgb_cv(X_TRAIN, y_TRAIN, params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXsP1wpiCe3X"
      },
      "source": [
        "# # LGBM Feature importance\n",
        "# plt.rcParams['figure.figsize'] = (18.0, 4)\n",
        "# fig, ax = plt.subplots(figsize=(12,8))\n",
        "# lgb.plot_importance(lgb_model, max_num_features=50, height=0.8, ax=ax)\n",
        "# ax.grid(False)\n",
        "# plt.title(\"LightGBM - Feature Importance \", fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHYenTnFET__"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfnkZGi-L8Ln"
      },
      "source": [
        "def svm_train_pred(xtrain, ytrain, xtest, ytest, model, name=\"SVM\"):\n",
        "  start_time = datetime.now()\n",
        "  # Train and predict\n",
        "  model = model.fit(xtrain, ytrain)\n",
        "  ytrain_prob = model.predict(xtrain)\n",
        "  ytest_prob = model.predict(xtest)\n",
        "  ytrain_pred = np.round(ytrain_prob)\n",
        "  ytest_pred = np.round(ytest_prob)\n",
        "  # Evaluate\n",
        "  print(f\"{name} train accuracy: {get_accuracy(ytrain_pred, ytrain)}\")\n",
        "  print(f\"{name} test accuracy: {get_accuracy(ytest_pred, ytest)}\")\n",
        "  # Report time \n",
        "  print(f\"Duration: {datetime.now() - start_time}\")\n",
        "  return model, ytrain_prob, ytrain_pred, ytest_prob, ytest_pred\n",
        "\n",
        "svm_rbf = svm.SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\n",
        "svm_model, svm_train_yprob, svm_train_ypred, svm_test_yprob, svm_test_ypred = svm_train_pred(X_train, y_train, X_val, y_val, model=svm_rbf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCj8J9kKljtr"
      },
      "source": [
        "# SVM CV\n",
        "def svm_cv(xtrain, ytrain, model, kfold=10, name=\"SVM\"):\n",
        "  start_time = datetime.now()\n",
        "  print(f\"Performing {name} CV\")\n",
        "  # Initialize 1d df to store predictions and true values\n",
        "  train_yprob_vec, train_ypred_vec, train_ytrue_vec = np.array([]), np.array([]), np.array([])\n",
        "  val_yprob_vec, val_ypred_vec, val_ytrue_vec = np.array([]), np.array([]), np.array([])\n",
        "  # Stratified CV\n",
        "  skf = StratifiedKFold(n_splits=kfold, shuffle=True, random_state=26)\n",
        "  for i, (itrain, ival) in enumerate(skf.split(xtrain, ytrain)):\n",
        "    print(f\"\\n> Starting CV iteration {i+1}\")\n",
        "    # Split data according to folds\n",
        "    X_train, X_val = X_TRAIN.iloc[itrain], X_TRAIN.iloc[ival]\n",
        "    y_train, y_val = y_TRAIN[itrain], y_TRAIN[ival]\n",
        "    # Normalization\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val = scaler.transform(X_val)\n",
        "    # Train and predict\n",
        "    _, train_yprob, train_ypred, val_yprob, val_ypred = svm_train_pred(X_train, y_train, X_val, y_val, model=model)\n",
        "    # Store prediction on training data\n",
        "    train_yprob_vec = np.concatenate((train_yprob_vec, train_yprob))\n",
        "    train_ypred_vec = np.concatenate((train_ypred_vec, train_ypred))\n",
        "    train_ytrue_vec = np.concatenate((train_ytrue_vec, y_train))\n",
        "    # Store prediction on validation data\n",
        "    val_yprob_vec = np.concatenate((val_yprob_vec, val_yprob))\n",
        "    val_ypred_vec = np.concatenate((val_ypred_vec, val_ypred))\n",
        "    val_ytrue_vec = np.concatenate((val_ytrue_vec, y_val))\n",
        "  # Stack training and validation predictions into two panda df\n",
        "  train_output = pd.DataFrame({\"yprob\": train_yprob_vec, \"ypred\": train_ypred_vec,\"ytrue\": train_ytrue_vec})\n",
        "  val_output = pd.DataFrame({\"yprob\": val_yprob_vec, \"ypred\": val_ypred_vec,\"ytrue\": val_ytrue_vec})\n",
        "  # Evaluate\n",
        "  train_acc = get_accuracy(train_output[\"ypred\"].values, train_output[\"ytrue\"].values)\n",
        "  val_acc = get_accuracy(val_output[\"ypred\"].values, val_output[\"ytrue\"].values)\n",
        "  print(f\"\\n>> {name} final report\")\n",
        "  print(f\"Train CV accuracy: {train_acc:.4}\")\n",
        "  print(f\"Valid CV accuracy: {val_acc:.4}\")\n",
        "  # Report time \n",
        "  print(f\"Duration: {datetime.now() - start_time}\")\n",
        "  return train_output, val_output\n",
        "\n",
        "svm_train_output, svm_val_output = svm_cv(X_TRAIN, y_TRAIN, model=svm_rbf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmLix3t-D6ka"
      },
      "source": [
        "## Performance evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEs9IC-f8MWG"
      },
      "source": [
        "# Function to quickly add plot details\n",
        "def plot_details(title = \"\", xlabel = \"X-axis\", ylabel = \"Y-axis\",\n",
        "                 ax_equal = False, legend = True, leg_loc = None,\n",
        "                 grid = True, save = False, filename = False):\n",
        "    # Title and axis\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.xlabel(xlabel, fontsize=13)\n",
        "    plt.ylabel(ylabel, fontsize=13)\n",
        "    if ax_equal == True:\n",
        "        plt.axis('equal') \n",
        "    # Legend and grid\n",
        "    if legend == True:\n",
        "        legend = plt.legend(frameon = 1, loc = leg_loc, shadow = True)\n",
        "        frame = legend.get_frame()\n",
        "        frame.set_facecolor('white')\n",
        "        frame.set_edgecolor('black')\n",
        "    if grid == True:\n",
        "        plt.grid(zorder=0, color=\"lightgray\")\n",
        "    # Output\n",
        "    if save == True:\n",
        "        plt.savefig(filename + \".png\", dpi = 300)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys1o-nFWExgm"
      },
      "source": [
        "#### Classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgxhz1_eD_gG"
      },
      "source": [
        "print(\"Random forest:\\n\", classification_report(rf_val_output[\"ytrue\"], rf_val_output[\"ypred\"]))     \n",
        "print(\"LightGBM:\\n\",classification_report(lgb_val_output[\"ytrue\"], lgb_val_output[\"ypred\"]))\n",
        "print(\"SVM RBF:\\n\",classification_report(svm_val_output[\"ytrue\"], svm_val_output[\"ypred\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn5L20dBFa4j"
      },
      "source": [
        "#### ROC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa17Pl1vFcji"
      },
      "source": [
        "# Compute FPR and TPR\n",
        "rf_val_auc = roc_auc_score(rf_val_output[\"ytrue\"], rf_val_output[\"ypred\"])\n",
        "fpr_rf, tpr_rf, _ = roc_curve(rf_val_output[\"ytrue\"], rf_val_output[\"yprob\"])\n",
        "lgb_val_auc = roc_auc_score(lgb_val_output[\"ytrue\"], lgb_val_output[\"ypred\"])\n",
        "fpr_lgb, tpr_lgb, _ = roc_curve(lgb_val_output[\"ytrue\"], lgb_val_output[\"yprob\"])\n",
        "svm_val_auc = roc_auc_score(svm_val_output[\"ytrue\"], svm_val_output[\"ypred\"])\n",
        "fpr_svm, tpr_svm, _ = roc_curve(svm_val_output[\"ytrue\"], svm_val_output[\"yprob\"])\n",
        "\n",
        "# Plot ROC\n",
        "fig, ax = plt.subplots(1, 1, figsize = (6, 4))\n",
        "ax.plot(fpr_rf, tpr_rf, label=f\"RF (AUC = {rf_val_auc:.3})\")\n",
        "ax.plot(fpr_lgb, tpr_lgb, label=f\"LGBM (AUC = {lgb_val_auc:.3})\")\n",
        "ax.plot(fpr_svm, tpr_svm, label=f\"SVM RBF (AUC = {svm_val_auc:.3})\")\n",
        "ax.plot([0, 1], [0, 1],'r--')\n",
        "plot_details(title = \"ROC on validation data (CV)\",\n",
        "             xlabel = '1 - Specificity (FPR)', \n",
        "             ylabel = 'Sensitivity (TPR)',\n",
        "             leg_loc = \"lower right\",\n",
        "             save = True,\n",
        "             filename = \"Plots/roc_rf_lgbm_all_replicate_negFiltered\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0YmmlNqeQBB"
      },
      "source": [
        "#### Plot some metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0CXdUrKsx0k"
      },
      "source": [
        "# RF\n",
        "rf_train_auc = roc_auc_score(rf_train_output[\"ytrue\"], rf_train_output[\"ypred\"])\n",
        "rf_train_acc = get_accuracy(rf_train_output[\"ypred\"], rf_train_output[\"ytrue\"])\n",
        "rf_train_rmse = rmse(rf_train_output[\"yprob\"], rf_train_output[\"ytrue\"])\n",
        "rf_val_acc = get_accuracy(rf_val_output[\"ypred\"], rf_val_output[\"ytrue\"])\n",
        "rf_val_rmse = rmse(rf_val_output[\"yprob\"], rf_val_output[\"ytrue\"])\n",
        "# LGBM\n",
        "lgb_train_auc = roc_auc_score(lgb_train_output[\"ytrue\"], lgb_train_output[\"ypred\"])\n",
        "lgb_train_acc = get_accuracy(lgb_train_output[\"ypred\"], lgb_train_output[\"ytrue\"])\n",
        "lgb_train_rmse = rmse(lgb_train_output[\"yprob\"], lgb_train_output[\"ytrue\"])\n",
        "lgb_val_acc = get_accuracy(lgb_val_output[\"ypred\"], lgb_val_output[\"ytrue\"])\n",
        "lgb_val_rmse = rmse(lgb_val_output[\"yprob\"], lgb_val_output[\"ytrue\"])\n",
        "# SVM\n",
        "svm_train_auc = roc_auc_score(svm_train_output[\"ytrue\"], svm_train_output[\"ypred\"])\n",
        "svm_train_acc = get_accuracy(svm_train_output[\"ypred\"], svm_train_output[\"ytrue\"])\n",
        "svm_train_rmse = rmse(svm_train_output[\"yprob\"], svm_train_output[\"ytrue\"])\n",
        "svm_val_acc = get_accuracy(svm_val_output[\"ypred\"], svm_val_output[\"ytrue\"])\n",
        "svm_val_rmse = rmse(svm_val_output[\"yprob\"], svm_val_output[\"ytrue\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr1Sg5uh_DjJ"
      },
      "source": [
        "train_acc = rf_train_acc, lgb_train_acc, svm_train_acc\n",
        "train_rmse = rf_train_rmse, lgb_train_rmse, svm_train_rmse\n",
        "train_auc = rf_train_auc, lgb_train_auc, svm_train_auc\n",
        "\n",
        "val_acc = rf_val_acc, lgb_val_acc, svm_val_acc\n",
        "val_rmse = rf_val_rmse, lgb_val_rmse, svm_val_rmse\n",
        "val_auc = rf_val_auc, lgb_val_auc, svm_val_auc\n",
        "\n",
        "# Plot\n",
        "pd_df2 = pd.DataFrame({\"Train RMSE\": train_rmse, \"Train Acc\": train_acc, \"Train AUC\": train_auc,\n",
        "                       \"Val RMSE\": val_rmse, \"Val Acc\": val_acc, \"Val AUC\": val_auc}, \n",
        "                      index = [\"RF\", \"LGBM\", \"SVM\"])\n",
        "\n",
        "ax = pd_df2.plot(y=[\"Train RMSE\", \"Train Acc\", \"Train AUC\", \"Val RMSE\", \"Val Acc\", \"Val AUC\"], \n",
        "                 ylim=(0,1.1), figsize=(12,5), fontsize=13,\n",
        "                 kind=\"bar\", zorder=3, ec =\"black\",\n",
        "                 rot=1, width=0.8, color = [\"gold\", \"tab:orange\", \"tab:red\",\n",
        "                                                       \"tab:cyan\", \"cornflowerblue\", \"tab:blue\"])\n",
        "# Add details\n",
        "plt.title(\"Model performance evaluation\", fontsize = 15)\n",
        "plt.ylabel(\"Score\", fontsize = 13)\n",
        "plt.grid(axis=\"y\", zorder=0, color=\"lightgray\")  \n",
        "legend = plt.legend(frameon = 1, shadow = True, bbox_to_anchor=(1.03, 0.6), fontsize=13)\n",
        "frame = legend.get_frame()\n",
        "frame.set_facecolor('white')\n",
        "frame.set_edgecolor('black')\n",
        "# Annotate scores on top of the bars\n",
        "for p in ax.patches:\n",
        "  height = p.get_height()\n",
        "  ha = {'center': 'center', 'right': 'left', 'left': 'right'}\n",
        "  xpos='center'\n",
        "  offset = {'center': 0, 'right': 1, 'left': -1}\n",
        "  ax.annotate(f\"{height:.2}\",\n",
        "              xy=(p.get_x() + p.get_width() / 2, height),\n",
        "              xytext=(offset[xpos]*3, 3),  \n",
        "              textcoords=\"offset points\",  \n",
        "              ha=ha[xpos], va='bottom')\n",
        "plt.savefig(\"Plots/models_performance_all_replicate_negFiltered_validation2.png\", \n",
        "            dpi = 300, bbox_extra_artists=(legend,), bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}